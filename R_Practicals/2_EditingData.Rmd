---
title: "Practical 2: Editing and Visualising Data in R"
subtitle: "Biotech 7005: Bioinformatics and Systems Modelling"
author: "Steve Pederson"
date: "31 July 2017"
output: 
  html_document: 
    fig_caption: yes
    toc: yes
    toc_depth: 2
---

```{r, echo = FALSE}
library(knitr)
opts_chunk$set(echo = TRUE,
               # eval = FALSE,
               results = "hide",
               message = FALSE, warning =  FALSE)
```


# Working with Data Frames

## Introduction

This is also known as _data munging_ and is one of the most common processes in any bioinformatics analysis.

We'll cover:

- `SQL-` and `Excel-`like functions in `dplyr`
    - `select()`: selecting and rearranging columns
    - `rename()`: renaming columns
    - `mutate()`: creating and overwriting columns
    - `arrange()`: reordering columns
    - `summarise()`: obtaining summary values for a column
    - `group_by()`: defining grouping variables for summaries
- Changing from wide to long form using `reshape2`
    - `melt()`: changing from wide to long form
    - `dcast()`: changing from long to wide form
- Editing text using `stringr`
    - `str_extract_all()`: using regular expressions to extract patterns within strings


The datasets required are contained in the files 1) `transport.csv` and 2) `pcr.csv`




<!-- ## But First | Logical Tests  -->

<!-- - Is Equal To: `==` -->
<!-- - Not equal - `!=` -->
<!-- - OR - `|` -->
<!-- - Less than `<` -->
<!-- - Less than or equal `<=` -->

<!-- ## Logical Tests -->

<!-- ```{r, results='hide'} -->
<!-- x <- 1:10 -->
<!-- x == 5 -->
<!-- x !=5 -->
<!-- x > 5 -->
<!-- x > 5 | x == 2 -->
<!-- ``` -->

<!-- - `R` also recognises the symbol `&` for `AND` -->
<!-- - Not relevant for `dplyr` -->

# The package `dplyr`

## Starting with `dplyr`

Data for this session:

```{r, results='hide'}
library(dplyr)
library(readr)
csvFile <- file.path("data", "transport.csv")
file.exists(csvFile)
data <- read_csv(csvFile)
data
```

So we have a `r nrow(data)` x `r ncol(data)` `data frame`, which has the familiar structure of rows and columns. 
We can check the dimensions of this object.

```{r, results='hide'}
dim(data)
nrow(data)
ncol(data)
```

Our tasks will be to:

- remove any meaningless columns
- count how many of each gender use each transport method
- add a column with BMI

### Subsetting a `data.frame`

The conventional `R` method of subsetting a `data.frame` is to use the square brackets (`[]`) and specify rows/columns by position or by name.

For example, to get back the first value of the second column we could type:

```{r}
data[1, 2]
```

Or we could get back the first 5 names

```{r}
data[1:5, "name"]
```

The package `dplyr` has an additional method of selecting columns, by using the function `select()`.

```{r}
select(data, name, transport)
```

*Note that we have only printed the results to the screen and haven't created any new `R` objects.*

An advantage of this method, as opposed to the square brackets is the use of some helper functions `starts_with()`, `ends_with()`, `contains()` and `everything()`.
We can use these to reorder the columns easily.
Try the following, and you'll see how useful this can be.

```{r}
select(data, name, everything())
select(data, ends_with("ght"))
select(data, contains("a"))
```

We can also use the `-` sign before a name to remove columns.

```{r}
select(data, -name)
```

It looks like the frst column (`X1`) is actually just the rownames written to the file when saved by our collaborators.
Let's remove that column, and this time we'll over-write the object.
**If you haven't been keeping track of the above in your script, this would be an important line to put there as we are overwriting the original object.**
If we delete a column and then realise we need it back , we can just rerun our code to reload the object.

```{r}
data <- select(data, -X1)
```

In the function `select()`, we can also use column numbers but in general it is best practice to use column names.
*Why would this be?*

### Adding extra columns

We can add extra columns using `mutate()`.
It's clear that the height here is provided in *cm*, but for BMI calculations we'll need height in *m*.
We can add a column and perform calculations add the same time.

```{r}
mutate(data, height_m = height/100)
```

We can also perform multiple column additions in the same step.

```{r}
mutate(data, height_m = height/100, BMI = weight / height_m^2)
```

Note that we haven't overwritten our original object, so let's add those columns permanently to our `data.frame`.
**Don't forget to add this line to your script!**

```{r}
data <- mutate(data, height_m = height/100, BMI = weight / height_m^2)
```

### Renaming columns

Now we have a column called `height` and another called `height_m` so it might be sensible to rename our original column as `height_cm` to make this clear.
The function `rename()` is all we need to perform this action.
This time we'll just overwrite the new version of `data` straight away.

```{r}
data <- rename(data, height_cm = height)
data
```

### Filtering data

Many of us are familiar with the Auto-filter in Excel, and `dplyr` has equivalent function, called `filter()`.
We can use logical tests to build up complex filtering criteria.
Again, note that in the next few lines, we are not overwriting our object but are just exploring our data.


```{r}
filter(data, gender == "male")
```

Notice that in the above line we used the double equals (`==`) sign.
This is common syntax in most programming languages, whilst a single equals sign (`=`) usually means we are assigning a value to an object or variable.
To perform the test *not equal to*, we replace the first equals sign with an exclamation mark (`!`).


```{r}
filter(data, gender != "male")
```

We can build up complex filters by adding them inside the filter function with a comma between them.

```{r}
filter(data, gender == "male", height_cm > 175)
filter(data, transport == "car", gender == "female")
```

### Sorting columns

We can also use the function `arrange()` to sort our data, just like the sort function in Excel.
By default, values are sorted in ascending order, so to reverse this we just wrap the column name in `desc()`.

```{r}
arrange(data, weight)
arrange(data, desc(weight))
```

We can also sort on multiple columns in the same line.

```{r}
arrange(data, transport, height_cm)
```


### Combining Functions using `%>%`

This is where `dplyr` steps up a gear.
We can chain functions together using the symbol `%>%`, which behaves like a pipe symbol (`|`) in the bash shell.
This function/symbol is called *The Magrittr* or *The Pipe* after a [famous painting by Rene Magritte](https://en.wikipedia.org/wiki/The_Treachery_of_Images)
It is contained in the package `magrittr`, and is loaded by `dplyr` every time we load `dplyr`.

The `%>%` symbol places whatever precedes it as the first argument of the next function.
An alternative way to write our previous line of code would be:

```{r}
data %>% arrange(transport, height_cm)
```

We can now use this to combine functions into a longer chain of commands, and there is __no limit__ to the number of functions you can chain together.

```{r}
data %>% filter(transport == "bike") %>% arrange(weight)
```

This specifically works here because every function takes a `data.frame` as input, and provides a `data.frame` as output.
From this point forward, we'll use this as our standard syntax when using `dplyr` functions.

As we're now able to build up long chains of commands, we can also spread our code over multiple lines.
Ending a line with `%>%` symbol let's `R` know that another line is coming.
This has the dual advantage of being easier to read later, and enabling us to write comments at the end of each line.

```{r}
data %>% # Take our original dataset
  filter(transport == "bike") %>%  # Find the cyclists
  arrange(weight) # Arrange by weight
```

### Getting Summaries

We can get summaries for entire columns:

```{r}
data %>% summarise(mean(weight), mean(height_cm))
```

Or we could chain together a few commands, and provide new names for our sumary columns.

```{r}
data %>%
  filter(gender == "female",
         transport == "bike") %>%
  summarise(max_BMI = max(BMI), 
            mn_height = mean(height_cm))
```

We can use any function here that returns a single value, such as `min()`, `max()`, `mean()`, `sd()`, `median()` etc.

As an additionally useful feature, we can group categorical variables by their levels, and even count how many measurements we have.

```{r}
data %>%
  group_by(gender, transport) %>%
  summarise(mn_weight = mean(weight), 
            mn_height =mean(height_cm),
            mn_BMI = mean(BMI),
            n = n())
```

As you can see, this is very similar to Excel, except we don't have to repeat anything if new data arrives.
We just load the now file, and run our code.
And we can remember exactly what we've done, withouth accidentally over-writing our original data.
It's all happened in `R` while our original file is still unchanged on our hard-drive.
This can aid with reproducible research, and also help prevent catastrophes.


# Reshaping Data and Regular Expressions

## The package `reshape2`

### Wide Form Vs Long Form

In this section we will need the `pcr.csv` dataset in the data folder.
Let's load the data first.

```{r}
pcrFile <- file.path("data", "pcr.csv")
file.exists(pcrFile)
pcrData <- read_csv(pcrFile)
```

Here we have RT-PCR data from T cells as a time course for two treatments (Resting and Stim).
The values are `Ct` values and we have three genes under investigation.

This dataset is in what we refer to as `wide` form where we have a row of measurements for each individual gene.
The information is _structured around the gene_.
In `long` form, the information would be  _structured around the measurement_.

To perform this in`R` we can simply use the package `reshape2`, and the function `melt()`

```{r}
library(reshape2)
melt(pcrData, id.vars = "Gene")
```

Notice that this has held the `Gene` column fixed but the remainder of the columns have been 'melted' downthe screen, with the column names in a new column called `variable`, and the values in a column called `value`.
Now you can see that we have a unique row for each measurement, containing all the information about that measurement.

Let's save that as a new object, and give those columns better names while we're at it.

```{r}
pcrLong <- melt(pcrData, id.vars = "Gene", variable.name = "Treatment", value.name = "Ct")
head(pcrLong)
```

This time we have a plain `data.frame` without the pretty `tibble` wrapping paper on it, so can avoid the 'information dump' on our screens by looking at the first few rows using `head()`.

If we wanted to return this to wide form we can use the function `dcast()`.
NOw we are seeing the `R` formula syntax with the `~` symbol for the first time.
This can be taken to mean `depends on` and in this context that value before the `~` will produce the row variable, whilst the values following will produce the column variables.


```{r}
dcast(pcrLong, Gene~Treatment)
dcast(pcrLong, Treatment~Gene)
```

## Regular Expressions

As we can see, the `Treatment` column contains two piecs of information and we may want to place these in two separate columns.
The `mutate()` function would be a good choice, but how do we separate those values on either side of the `_` symbol?

For this we'll use the package `stringr` and discuss **regular expressions** first.
The key functions here will be `str_extract()`, `str_replace()` and `str_replace_all()`

```{r}
library(stringr)
```

### Text Manipulation 

Matching obvious patterns uses a simple syntax.
The first argument is the original `string`, which is follwed by the search `pattern` and the `replacement`.

```{r}
str_replace("Hi Mum", "Mum", "Dad")
```

Here we are searching the the `string` "Hi Mum" for the `pattern` "Mum", and replacing  with the string "Dad".

### Wild-cards

In regular expressions, we can specify wild-cards as `.` which means "match anything".

```{r}
str_replace("Hi Mum", "M..", "Dad")
```

We can also match any number of wild-cards by using `+`, so in the following we are searching for `M` followed by *anything*, *one or more times*.

```{r}
str_replace("Hi Mum", "M.+", "Dad")
str_replace("Hi Mother", "M.+", "Dad")
```

### Text captures

We can also capture words/phrases/patterns using the round brackets containing or target `(pattern)`.
We can then return these in the order we capture them by using the double backslash symbol followed by their capture number.
*This is `R`-specific syntax and doesn't apply when we move to bash in a few weeks*.

```{r}
str_replace("Hi Mother", "(M.+)(h.+)", "\\2\\1")
```

### Specific character sets

We can also specify specific strict alternatives instead of wild-cards y placing options inside square brackets (`[]`).
The function `str_replace()` will only replace the first instance in each string, whilst `str_replace_all()` will replace *all* instances.

```{r}
str_replace("Hi Mum", "[Mm]", "b")
str_replace_all("Hi Mum", "[Mm]", "b")
str_replace_all("Hi Mum", "[aeiou]", "o")
str_replace_all("Hi Mum", "[a-z]", "o")
```

### Alternative Patterns

Alternative patterns can be specified using the conventional `OR` symbol `|` inside the curved brackets.

```{r}
str_replace_all("Hi Mum", "(Mum|Dad)", "Parent")
str_replace_all("Hi Dad", "(Mum|Dad)", "Parent")
str_replace_all("Hi Dad", "Hi (Mum|Dad)", "Hello Parent")
```


### Returning to our data

Here we are going to use `str_extract` to grab our timepoint, and `str_replace()` to remove it from the `Treatment` column.

```{r}
pcrLong %>%
  mutate(TimePoint = str_extract(Treatment, "(0hr|12hr|24hr)"),
         Treatment = str_replace(Treatment, "_(0hr|12hr|24hr)", ""))
```

We could now combine this with our `select()` function to reorder the columns, whilst overwriting the previous version of the object.

```{r}
pcrLong <- pcrLong %>%
  mutate(TimePoint = str_extract(Treatment, "(0hr|12hr|24hr)"),
         Treatment = str_replace(Treatment, "_(0hr|12hr|24hr)", "")) %>%
  select(Gene, TimePoint, everything())
```

Once you're happy with all of the above processes, head to the Data Visualisation section.
