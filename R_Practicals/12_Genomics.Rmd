---
title: "A Introduction To R In The Genomics Era"
author: "Steve Pederson"
date: "12 September, 2016"
output: html_document
---

```{r, loadPackages, echo = FALSE, include = FALSE}
library(knitr)
opts_chunk$set(echo = TRUE, include = TRUE, 
               eval = FALSE,
               warning = FALSE, message = FALSE, 
               out.width = 800, fig.align = "center",
               results = 'hide')
```

# R Packages

- A Package is a collection of functions
- Associated with a given task/analysis/data-type
- The main repository is "__The Comprehensive R Archive Network__" (https://cran.r-project.org/)

`Tools > Install Packages...`

Go to the `Help` Tab

`Home` > `Packages` > `dplyr`

Here you can see all of the functions in `dplyr`

Many packages also define objects of a given `class`,  
e.g. a `data_frame`, `tbl_df` or `tibble`


# The Bioconductor Project 

The main repository for biologically focussed packages is [Bioconductor](http://www.bioconductor.org)

- All packages (~1200) are for Bioinformatics
    + Statistical Analysis; Databases & Data Handling; Visualisation
    + NGS data, microarrays, flow cytometry, proteomics...
- New releases every ~6 months
- All packages come with a descriptive vignette

```{r, eval=FALSE}
browseVignettes()
```

Also has an active support community:

- https://support.bioconductor.org/
- Large suite of tutorials & workflows

A recent training course:

http://www.bioconductor.org/help/course-materials/2016/BioC2016/

Some upcoming courses:

http://www.abacbs.org/biocasia2016workshop

## The Bioconductor Project

3 Broad Headings based on package tags, or `biocViews`

1. Software
2. AnnotationData
3. ExperimentData

### 1. Software

- Currently >1000 packages, primarily for analysis
- Heavily used array packages: `affy`, `gcrma`, `limma`
- Access to external databases: `biomaRt`, `topGO`
- Rich in Seq analysis packages: `edgeR`, `DESeq`, `RSamtools`
- Wrappers for external Seq tools: `muscle`, `RBowtie`
- Lots of new object classes defined

### 2. Annotation
- Currently >900 packages
- Set database classes (`OrgDb`, `TxDb`, `OrganismDb`, `BSgenome`)
- Annotations for common microarrays (e.g. Affy & Illumina)

### 3. Experiment Data
- Currently ~300 packages
- Includes standard datasets for algorithm testing
- Also those included in many training courses

Today we'll look mainly at some Annotation approaches.

## Installing Bioconductor

- Packages don't appear in the drop-down menu for *RStudio*
    + Tools > Install Packages > ???
- Can be added to your default repositories, but there is a preferred installation procedure.

Cut and paste the following lines into your R Session. 
Be aware that this may take a while to run.

```{r, eval=FALSE}
source("http://bioconductor.org/biocLite.R")
biocLite("GenomicRanges", "biomaRt", "AnnotationHub", "TxDb.Hsapiens.UCSC.hg19.knownGene", "RNAseqData.HNRNPC.bam.chr14", "airway", "DESeq2", "edgeR", "limma")
```

- This installs the package `BiocInstaller`
- Manages the synchronisation of *R* releases and Bioconductor updates
- The main installation function is `biocLite()`
- Installs from __both__ CRAN & Bioconductor

*R* dependencies can be challenging!
To check that you have the tested package versions and fix them

```{r, eval=FALSE}
library(BiocInstaller)
biocValid(fix = TRUE)
```

# Getting Annotation Information

## Annotation

- Make up a significant proportion of Bioconductor Packages
- Often seen as the end point of analysis
- For networks/pathways it's the starting point

## `biomaRt`

The package `biomaRt` is based on the web interface at http://www.ensembl.org/biomart/martview


```{r, eval=FALSE, message=FALSE}
library(biomaRt)
allMarts <- listMarts()
```

These are the possible data sources (i.e. marts) we can access
Each `mart` has multiple `datasets`.

Note, we're using `dplyr::filter()` to just get the human datsets.

```{r}
mart <- useMart("ENSEMBL_MART_ENSEMBL")
ensDatasets <- listDatasets(mart)
library(dplyr)
filter(ensDatasets, grepl("sapiens", dataset))
```

We can just go straight there by selecting the `dataset` within `useMart()`

```{r}
mart <- useMart(biomart = "ENSEMBL_MART_ENSEMBL", 
                dataset = "hsapiens_gene_ensembl")
```

NB: This is exactly the same procedure as the windows on the web GUI

Now the `mart` & `dataset` have been selected

- The main query function is `getBM()`

```{r}
?getBM
```

This will give the requested data directly into a `data.frame`

### Attributes and Filters

The two main pieces of data

- `attributes` are the values we are looking for
- `filter` along with `values` are our search queries

To find what attributes can be downloaded from our `mart`

```{r}
martAttributes <- listAttributes(mart)
```

These are possible pieces of information we can return (`dim(martAttributes)`)

- Some attributes may contain large amounts of data
- We can use filters to restrict the information
- e.g. we may have only a few genes of interest

```{r}
martFilters <- listFilters(mart)
```


### Example 1

- Let's get all the gene names on Chromosome 1
- NB: We need to specify the filter, and give the filter values separately
- We need to specify the mart argument every time

```{r}
genes <- getBM(attributes=c("hgnc_symbol", "entrezgene"), 
               filters = "chromosome_name", 
               values = "1", mart = mart)
head(genes)
```

### Example 2

Or we could get some information about two genes we're interested in.

```{r}
ids <- c("ENSG00000134460", "ENSG00000163599")
attr <-  c("ensembl_gene_id", "ensembl_transcript_id")
test <- getBM(attributes = attr,
              filters = "ensembl_gene_id",
              values = ids,
              mart = mart)
```

Repeat the above **without asking for the gene_id back**

### Task for you to figure out
How could we also get the `chromosome`, `strand`, `start` & `end` positions in the above query


### A known issue with `biomaRt` and `dplyr`

Here's a problem

```{r}
?select
```

We now have more than one function called `select`

__How will `R` know which one to use"__

This is a well known problem

The specific version of a function can be called by using the package name, followed by a double colon `::`

- Known as the `namespace`
- `dplyr::select()` or `biomaRt::select()`

# Annotation Hub

```{r, message=FALSE}
library(AnnotationHub)
ah <- AnnotationHub()
```

- This is a relatively new & sensibly named package
- We can access & find numerous annotation types
- Uses `SQL`-type methods
- Creating this object will create a cache with the latest metadata from each data source

Get a summary of annotations we have:

```{r, eval=FALSE}
ah
```

- 3 important components: `$dataprovider`, `$species` & `$rdataclass`
- additional components listed under `additional mcols()` can also be accessed with the `$`

We can find the data providers

```{r, results='hide'}
unique(ah$dataprovider) 
```

Or the different data classes in the hub

```{r, results='hide'}
unique(ah$rdataclass) 
```

We can find the species with annotations

```{r}
sp <- unique(ah$species)
head(sp)
length(sp)
```

We can `query` for matches to any term, e.g. to look for rabbit (*Oryctolagus cuniculus*) annotation sources

```{r, results='hide', eval=FALSE}
query(ah, "Oryctolagus")
```

We can create smaller `AnnotationHub` objects, which we could then search again

We can subset easily

```{r, results='hide', eval=FALSE}
subset(ah, rdataclass=="GRanges")
```

Or if we know we want the `GRanges` annotations for the rabbit.

```{r, results='hide', eval=FALSE}
subset(query(ah, "Oryctolagus"), rdataclass=="GRanges")
```

This object type, is one of the building blocks for genomic analysis in R.
Here, each gene, exon or transcript is specified as a range enabling easy management of large genomic data objects.

Let's look at them further:

# `TxDb` Objects

These are the objects with the transcriptome information

- Saved using `GRanges` classes
- Derived heavily from the `GenomicRanges` & `IRanges` packages
- The key idea is to refer the the genome using ranges to define locations

First well load the human database and create it as an `R` object.

```{r, message=FALSE}
library(TxDb.Hsapiens.UCSC.hg19.knownGene)
txdb <- TxDb.Hsapiens.UCSC.hg19.knownGene   
```

```{r, eval=FALSE}
txdb
```

This will load all the package dependencies as well

## `GRanges` objects

Note that our `txdb` object used EntrezGene Ids.
We can actually create these ourselves using a `.gtf` file and the function `makeTxDbFromGFF()` but we'll just use a pre-made versin for now.

Let's extract, then look at a `GRanges` object.

```{r}
ids <- c(BRCA1="672", PTEN="5728")
genes(txdb, filter=list(gene_id=ids)) 
```

## `GRangesList` Objects

`GRanges` objects can also be extended to `GRangesList` objects

```{r}
exByGn <- exonsBy(txdb, "gene")
```

```{r, eval=FALSE}
exByGn
```

Now we have each gene as it's own "building-block" as part of a long list of genes.
The total number of genes is given by:

```{r}
length(exByGn)
```

And we can look at an individual gene using various methods

```{r}
exByGn[[1]]
exByGn$`1`
```

Note that in this object, each component of the `list` has a name, and this is the EntrezGeneID.
Ina bad design decision, these IDs are numbers but form characters.
See the difference here:

```{r}
exByGn[[2]]
exByGn$`2`
```

First we've called the second gene in the list, then we've called the gene with the ID `2`.
It's one of the many reasons some researchers prefer ENSEMBL IDs

As well as the `exonsBy()` methods, other methods include

- `transcriptsBy()`, `cdsBy()`, `threeUTRsByTranscript()` + more

In the current example exons are listed by gene, but can also be listed by `exon`, `cds` or `tx`


## The `TxDb` Object as a Database

As well as extracting `GRanges` from these objects, they share `SQL-like` methods with some other objects

```{r}
keytypes(txdb)
columns(txdb)
```

## `GenomicFeatures`

Loading a `TxDb` object will also load dependencies such as `GenomicFeatures`

Contains many useful functions

- `makeTxDbFromBiomart()`, `makeTxDbFromGFF()`, `makeTxDbFromGRanges()`, `makeTxDbFromUCSC()`


`TxDb` objects not currently accesible from `AnnotationHub` so we often need other source objects, e.g. GTF files.
A key feature of this approach is that they give the flexibility to use these methods for non-model organisms using our own annotations, genomes etc

`GenomicFeatures` also contains other useful methods.
Here we can just grab the promoter regions for every `UCSC` transcript.

```{r, eval=FALSE}
promoters(txdb, upstream=100, downstream=50,
          columns = c("tx_name", "gene_id"))
```

# GenomicAlignments

We can also work with alignments in R, and the [RNAseqData.HNRNPC.bam.chr14][] package is an example of an experiment data package. 
It contains a subset of BAM files used in a gene knock-down experiment, as described in `?RNAseqData.HNRNPC.bam.chr14`. 
Load the package and get the path to the BAM files.

```{r}
library(RNAseqData.HNRNPC.bam.chr14)
fls <- RNAseqData.HNRNPC.bam.chr14_BAMFILES
basename(fls)
```

Create `BamFileList()`, basically telling R that these are paths to BAM files rather than, say, text files from a spreadsheet.

```{r}
library(GenomicAlignments)
bfls <- BamFileList(fls)
bfl <- bfls[[1]]
```

Input and explore the aligments. See `?readGAlignments` and
`?GAlignments` for details on how to manipulate these objects.

```{r}
ga <- readGAlignments(bfl)
ga
table(strand(ga))
```

Many of the reads have cigar "72M". What does this mean? Can you
create a subset of reads that do not have this cigar? Interpret some
of the non-72M cigars. Any hint about what these cigars represent?

```{r}
tail(sort(table(cigar(ga))))
ga[cigar(ga) != "72M"]
```

Use the function `summarizeJunctions()` to identify genomic regions
that are spanned by reads with complicated cigars. Can you use the
argument `with.revmap=TRUE` to extract the reads supporting a
particular (e.g., first) junction?

```{r}
summarizeJunctions(ga)
junctions <- summarizeJunctions(ga, with.revmap=TRUE)
ga[ junctions$revmap[[1]] ]
```

It is possible to do other actions on BAM files, e.g., calculating the
'coverage' (reads overlapping each base).

```{r}
coverage(bfl)$chr14
```

# Other Resources

A detailed course on an RNASeq Workflow using `Bioconductor` can be found at http://bioconductor.org/help/course-materials/2016/BiocIntro-May/B3_RNASeq_Workflow.html.

This particular session uses all of the above, plus the data in the package `airway` and the analytic package `DESeq2`